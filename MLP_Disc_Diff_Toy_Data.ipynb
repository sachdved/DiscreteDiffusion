{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8605fcd-2201-40d2-850c-f7891db59663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from utils import *\n",
    "from architectures import *\n",
    "import preprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from CategoricalDiffusion import *\n",
    "from denoiser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d2efe8-6774-423d-8c03-725bb38e5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDenoiser(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_time,\n",
    "        d_seq,\n",
    "        d_aas,\n",
    "        d_model = 128,\n",
    "        p = 0.1,\n",
    "        activation = torch.nn.ReLU(),\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = activation\n",
    "        self.p = p\n",
    "\n",
    "\n",
    "        self.forward_time_seq = FeedForward(d_seq*d_aas + d_time, d_model)\n",
    "\n",
    "        self.forward_time_seq_1 = FeedForward(d_model, d_model)\n",
    "        self.dropout_1 = torch.nn.Dropout(self.p)\n",
    "        \n",
    "        self.forward_time_seq_2 = FeedForward(d_model, d_model)\n",
    "        self.dropout_2 = torch.nn.Dropout(self.p)\n",
    "        \n",
    "        self.forward_time_seq_3 = FeedForward(d_model, d_model)\n",
    "        self.dropout_3 = torch.nn.Dropout(self.p)\n",
    "\n",
    "        self.feedforward_final = FeedForward(d_model, d_seq*d_aas)\n",
    "        \n",
    "    def forward(self, X, t):\n",
    "\n",
    "        time_points, batch_size, seq_length, aas = X.shape[0], X.shape[1], X.shape[2], X.shape[3]\n",
    "        \n",
    "        t = t.reshape(t.shape[0] * t.shape[1], 1)\n",
    "        X = X.view(time_points*batch_size, seq_length, aas)\n",
    "        \n",
    "        X_flattened = torch.nn.Flatten(start_dim=1)(X)\n",
    "        \n",
    "        seq_time_encoding = torch.concat([t, X_flattened], dim=-1)\n",
    "\n",
    "        input_encoding = self.forward_time_seq(seq_time_encoding)\n",
    "\n",
    "        X_1 = self.forward_time_seq_1(input_encoding)\n",
    "        X_1 = self.activation(X_1)\n",
    "        X_1 = self.dropout_1(X_1)\n",
    "\n",
    "        X_2 = self.forward_time_seq_2(X_1)\n",
    "        X_2 = self.activation(X_2)\n",
    "        X_2 = self.dropout_2(X_2)\n",
    "\n",
    "        X_3 = self.forward_time_seq_3(X_2)\n",
    "        X_3 = self.activation(X_3)\n",
    "        X_3 = self.dropout_3(X_3)\n",
    "\n",
    "        X_final = self.feedforward_final(X_3)\n",
    "\n",
    "        X_final = X_final.view(time_points, batch_size, seq_length, aas)\n",
    "        \n",
    "        Y_pred = torch.nn.Softmax(dim=-1)(X_final)\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4bd5823-7041-418a-884c-ca1031c065b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:21<00:00,  4.56it/s]\n"
     ]
    }
   ],
   "source": [
    "N_samples = 10000\n",
    "\n",
    "M = 2\n",
    "N_dim = 100\n",
    "\n",
    "bias = torch.zeros((N_dim,1))\n",
    "patterns = 2*torch.bernoulli(torch.ones((N_dim, M)) * 0.5) - 1\n",
    "\n",
    "spins = generate_data(patterns, bias, N_samples, beta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338d12d8-6a9c-4938-b139-ad7ff32d9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_spins = ((1+spins)/2).type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343ebac6-c349-47b7-9f36-cb87fe85cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_spin_vectors = torch.nn.functional.one_hot(index_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbef2da4-18fd-41ba-96d5-682267df6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinsDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    takes in one hot encoded spins X with one key - sequence, and Y with one, potentially two, keys - sequence and phenotype\n",
    "    inputs:\n",
    "        one_hot_spins: torch.Tensor representing spins (num_samples, dim, num_states)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 spins,\n",
    "                 include_mask = False,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.include_mask = include_mask\n",
    "        self.spins = spins\n",
    "        if self.include_mask:\n",
    "\n",
    "            self.spins = torch.cat((self.spins, torch.zeros((self.spins.shape[0], self.spins.shape[1], 1))), axis=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.spins.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = dict()\n",
    "        Y = dict()\n",
    "\n",
    "        Y['spins'] = self.spins[index]\n",
    "        X['spins'] = self.spins[index]\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb26dae-688f-4860-8fe9-7579105db651",
   "metadata": {},
   "outputs": [],
   "source": [
    "spins_dataset = SpinsDataset(one_hot_spin_vectors, include_mask=True)\n",
    "spins_loader = torch.utils.data.DataLoader(spins_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e2131f-2ef3-4641-9512-9879531ea990",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in spins_loader:\n",
    "    X, Y = batch\n",
    "    X_spins = X['spins']\n",
    "    Y_spins = Y['spins']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dde4ff0-281f-4261-a652-ddfce207a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_matrix = Noiser(noiser = 'BERT-LIKE', beta_t = 0.01, k=2).noise_matrix\n",
    "ts, noised_samples = noiser(X_spins, noise_matrix, 200, X_spins.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da49505-e103-4358-a5fa-c6d25dcebf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 16, 100, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noised_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed3a9a-e00a-4a16-afd4-3ffd52296b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 100\n",
    "\n",
    "denoiser = MLPDenoiser(d_time = 1, d_seq = X_spins.shape[1], d_aas = X_spins.shape[2], d_model = 1024, p=0.9, activation = torch.nn.Tanh())\n",
    "cat_diff = CategoricalDiffusion(denoiser, noise_matrix)\n",
    "\n",
    "cat_diff.train()\n",
    "optim = torch.optim.Adam(cat_diff.parameters(), lr = 1e-3)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    overall_loss = 0\n",
    "    spins_loader = torch.utils.data.DataLoader(spins_dataset, batch_size=128, shuffle=True)\n",
    "    for batch in spins_loader:\n",
    "        X, Y = batch\n",
    "        \n",
    "        X_spins = X['spins']\n",
    "        Y_spins = Y['spins']\n",
    "        \n",
    "        ts, noised_samples = noiser(X_spins, noise_matrix, 200, X_spins.shape[-1])\n",
    "\n",
    "        cat_diff.decode(noised_samples, ts)\n",
    "        cat_diff.calc_forward_conditionals(noised_samples)\n",
    "        \n",
    "        LT_loss     = cat_diff.L_T(noised_samples)\n",
    "        \n",
    "        Lt0_t1_loss = cat_diff.L_t0t1(Y_spins)\n",
    "\n",
    "        Ltminus1    = cat_diff.L_tminus1(Y_spins, noised_samples)\n",
    "\n",
    "\n",
    "        loss = Lt0_t1_loss + Ltminus1\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #torch.nn.utils.clip_grad_value_(cat_diff.parameters(), 0.1)\n",
    "\n",
    "        optim.step()\n",
    "        if np.isnan(loss.item()):\n",
    "            break\n",
    "            \n",
    "        overall_loss += loss.item()\n",
    "    if np.isnan(loss.item()):\n",
    "        break\n",
    "    print('overall loss at epoch {} is '.format(epoch) + str(overall_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965c745-a018-4eb6-9d44-992afbb7eb05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noised_samples[99][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cbb88f-6834-485c-8af3-11930020b6a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_diff.y_pred[99][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "03da8669-1401-4c0d-9f75-6836e4eba60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = cat_diff.y_pred[2:]\n",
    "\n",
    "px_tminus1_giv_xt = q_xtminus1_xt_giv_x0 * denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3b0281aa-033a-48f7-b36e-e66f753d6818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000e+00, 3.1462e-01, 0.0000e+00],\n",
       "          [3.5677e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.3245e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.2670e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0302e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 2.9244e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.3716e-01, 0.0000e+00],\n",
       "          [3.2219e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [2.9704e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.2619e-01, 0.0000e+00],\n",
       "          [3.6161e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [2.8870e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.0515e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.1967e-01, 0.0000e+00],\n",
       "          [3.1448e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.8615e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0698e-01, 0.0000e+00],\n",
       "          [3.2339e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 1.5856e-01, 3.2519e-03],\n",
       "          [3.3326e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2670e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.3106e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2086e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.1995e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.2948e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3625e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2670e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.8064e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0472e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2592e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.2670e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.6159e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.4483e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.4310e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.5662e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.2670e-01, 0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 3.3722e-01, 0.0000e+00],\n",
       "          [3.1850e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.4382e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.2148e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.4507e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3020e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.0407e-01, 0.0000e+00],\n",
       "          [3.6837e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.2343e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.2343e-01, 0.0000e+00],\n",
       "          [3.3788e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.4038e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.4823e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0180e-01, 0.0000e+00],\n",
       "          [3.3380e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.2256e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2715e-01, 0.0000e+00],\n",
       "          [3.0749e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 8.7965e-02, 5.4671e-03],\n",
       "          [3.1709e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2343e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.1614e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 2.6522e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 2.9581e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.1504e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0370e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2343e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.1425e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0266e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 1.1164e-01, 6.4808e-03]],\n",
       "\n",
       "         [[3.5002e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.1669e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3298e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.2343e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0823e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0815e-01, 0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 3.3066e-01, 0.0000e+00],\n",
       "          [3.3928e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0747e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.8212e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0885e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.6789e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 2.9206e-01, 0.0000e+00],\n",
       "          [3.2165e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.3117e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.1823e-01, 0.0000e+00],\n",
       "          [3.3278e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.1436e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.2958e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2058e-01, 0.0000e+00],\n",
       "          [3.1537e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.6215e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3315e-01, 0.0000e+00],\n",
       "          [3.2449e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 7.6083e-02, 1.0498e-02],\n",
       "          [2.9603e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 2.9741e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.2020e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2264e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3696e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.1637e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2020e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0711e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.1888e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.2946e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 8.7624e-02, 9.3493e-03]],\n",
       "\n",
       "         [[3.4573e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.4582e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.1756e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.4381e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [7.8847e-02, 0.0000e+00, 9.9003e-03],\n",
       "          [2.8895e-01, 0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 3.7909e-04, 4.1565e-01],\n",
       "          [1.1423e-03, 0.0000e+00, 2.2191e-01],\n",
       "          [5.8507e-04, 0.0000e+00, 1.2066e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.7304e-04, 3.0467e-01],\n",
       "          [0.0000e+00, 4.0612e-04, 4.0841e-01],\n",
       "          [0.0000e+00, 7.6940e-04, 2.0632e-01]],\n",
       "\n",
       "         [[0.0000e+00, 5.3297e-04, 2.4242e-01],\n",
       "          [7.2225e-04, 0.0000e+00, 2.2855e-01],\n",
       "          [7.6940e-04, 0.0000e+00, 2.0632e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 7.6940e-04, 2.0632e-01],\n",
       "          [7.6297e-04, 0.0000e+00, 2.0976e-01],\n",
       "          [6.2826e-04, 0.0000e+00, 2.3843e-01]],\n",
       "\n",
       "         [[0.0000e+00, 6.9511e-04, 1.8640e-01],\n",
       "          [0.0000e+00, 4.6922e-04, 3.6730e-01],\n",
       "          [7.6940e-04, 0.0000e+00, 2.0632e-01],\n",
       "          ...,\n",
       "          [5.9710e-04, 0.0000e+00, 2.9872e-01],\n",
       "          [0.0000e+00, 5.9034e-04, 3.0234e-01],\n",
       "          [5.8848e-04, 0.0000e+00, 3.0334e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 6.6684e-04, 1.9659e-01],\n",
       "          [7.5912e-04, 0.0000e+00, 2.1183e-01],\n",
       "          [0.0000e+00, 7.7719e-04, 2.0527e-01],\n",
       "          ...,\n",
       "          [7.4850e-04, 0.0000e+00, 2.1752e-01],\n",
       "          [0.0000e+00, 7.0018e-04, 1.8250e-01],\n",
       "          [0.0000e+00, 7.6940e-04, 2.0632e-01]],\n",
       "\n",
       "         [[6.1240e-04, 0.0000e+00, 2.9052e-01],\n",
       "          [0.0000e+00, 1.0043e-03, 2.1995e-01],\n",
       "          [0.0000e+00, 6.5847e-04, 2.6581e-01],\n",
       "          ...,\n",
       "          [5.5107e-04, 0.0000e+00, 3.2341e-01],\n",
       "          [5.1028e-04, 0.0000e+00, 3.4528e-01],\n",
       "          [0.0000e+00, 8.2352e-04, 1.9133e-01]],\n",
       "\n",
       "         [[9.9928e-04, 0.0000e+00, 1.7550e-01],\n",
       "          [5.6144e-04, 0.0000e+00, 3.1785e-01],\n",
       "          [0.0000e+00, 6.8461e-04, 2.1139e-01],\n",
       "          ...,\n",
       "          [8.1555e-04, 0.0000e+00, 1.5929e-01],\n",
       "          [7.4270e-04, 0.0000e+00, 2.2063e-01],\n",
       "          [6.8001e-04, 0.0000e+00, 2.5426e-01]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 6.2419e-04, 2.7702e-01],\n",
       "          [6.2415e-04, 0.0000e+00, 2.3417e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 7.4954e-04, 2.0759e-01],\n",
       "          [0.0000e+00, 4.9372e-04, 1.6831e-01],\n",
       "          [0.0000e+00, 7.4954e-04, 2.0759e-01]],\n",
       "\n",
       "         [[0.0000e+00, 6.7042e-04, 1.7931e-01],\n",
       "          [8.1981e-04, 0.0000e+00, 2.1633e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 7.3227e-04, 2.2773e-01],\n",
       "          [8.1097e-04, 0.0000e+00, 1.9908e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01]],\n",
       "\n",
       "         [[0.0000e+00, 7.2805e-04, 2.0163e-01],\n",
       "          [0.0000e+00, 7.3321e-04, 2.0630e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          ...,\n",
       "          [7.4690e-04, 0.0000e+00, 2.0905e-01],\n",
       "          [0.0000e+00, 7.3979e-04, 2.0055e-01],\n",
       "          [7.6551e-04, 0.0000e+00, 2.0245e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 7.4153e-04, 2.0537e-01],\n",
       "          [7.9015e-04, 0.0000e+00, 1.9154e-01],\n",
       "          [0.0000e+00, 7.2907e-04, 2.1708e-01],\n",
       "          ...,\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          [0.0000e+00, 7.2993e-04, 2.0216e-01],\n",
       "          [0.0000e+00, 7.7022e-04, 1.9826e-01]],\n",
       "\n",
       "         [[7.5745e-04, 0.0000e+00, 2.3313e-01],\n",
       "          [0.0000e+00, 6.9705e-04, 2.3667e-01],\n",
       "          [0.0000e+00, 7.2789e-04, 2.0094e-01],\n",
       "          ...,\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          [1.0090e-03, 0.0000e+00, 1.7166e-01],\n",
       "          [0.0000e+00, 7.1179e-04, 2.2850e-01]],\n",
       "\n",
       "         [[7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          [6.9930e-04, 0.0000e+00, 2.3542e-01],\n",
       "          [0.0000e+00, 6.7917e-04, 2.3259e-01],\n",
       "          ...,\n",
       "          [7.6032e-04, 0.0000e+00, 2.0610e-01],\n",
       "          [8.4695e-04, 0.0000e+00, 2.0037e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 7.3587e-04, 1.9927e-01],\n",
       "          [7.1227e-04, 0.0000e+00, 2.0369e-01],\n",
       "          [7.3028e-04, 0.0000e+00, 2.0885e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 6.9042e-04, 2.3164e-01],\n",
       "          [0.0000e+00, 7.0599e-04, 2.2274e-01],\n",
       "          [0.0000e+00, 7.0283e-04, 2.1575e-01]],\n",
       "\n",
       "         [[0.0000e+00, 7.5273e-04, 1.9288e-01],\n",
       "          [7.3204e-04, 0.0000e+00, 2.2124e-01],\n",
       "          [7.3028e-04, 0.0000e+00, 2.0885e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 7.4048e-04, 2.1745e-01],\n",
       "          [8.1192e-04, 0.0000e+00, 1.9717e-01],\n",
       "          [8.4004e-04, 0.0000e+00, 1.9564e-01]],\n",
       "\n",
       "         [[0.0000e+00, 7.3111e-04, 1.6817e-01],\n",
       "          [0.0000e+00, 6.2841e-04, 2.6711e-01],\n",
       "          [8.2073e-04, 0.0000e+00, 2.3377e-01],\n",
       "          ...,\n",
       "          [7.5608e-04, 0.0000e+00, 2.0516e-01],\n",
       "          [0.0000e+00, 6.2543e-04, 1.7886e-01],\n",
       "          [7.7498e-04, 0.0000e+00, 2.0334e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 1.0958e-03, 1.5658e-01],\n",
       "          [5.5401e-04, 0.0000e+00, 2.2553e-01],\n",
       "          [0.0000e+00, 6.7116e-04, 1.7928e-01],\n",
       "          ...,\n",
       "          [5.4571e-04, 0.0000e+00, 3.1441e-01],\n",
       "          [0.0000e+00, 7.2986e-04, 2.0908e-01],\n",
       "          [0.0000e+00, 7.3028e-04, 2.0885e-01]],\n",
       "\n",
       "         [[7.9693e-04, 0.0000e+00, 1.7161e-01],\n",
       "          [0.0000e+00, 6.9062e-04, 1.9751e-01],\n",
       "          [0.0000e+00, 4.5239e-04, 1.5962e-01],\n",
       "          ...,\n",
       "          [7.3028e-04, 0.0000e+00, 2.0885e-01],\n",
       "          [9.1702e-04, 0.0000e+00, 1.7157e-01],\n",
       "          [0.0000e+00, 1.1570e-03, 1.4782e-01]],\n",
       "\n",
       "         [[1.2283e-03, 0.0000e+00, 1.3519e-01],\n",
       "          [1.2280e-03, 0.0000e+00, 1.3768e-01],\n",
       "          [0.0000e+00, 7.3028e-04, 2.0885e-01],\n",
       "          ...,\n",
       "          [3.8107e-04, 0.0000e+00, 4.0858e-01],\n",
       "          [8.8149e-04, 0.0000e+00, 1.8722e-01],\n",
       "          [7.2787e-04, 0.0000e+00, 2.0816e-01]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px_tminus1_giv_xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "813b7f46-7726-4729-a299-bc61557e6f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(\n",
    "            torch.sum(\n",
    "                cat_diff.forward_conditionals[2:] * (\n",
    "                    stuff * torch.log(\n",
    "                        (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "                    )\n",
    "                ),\n",
    "                axis=-1\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b01c4bb4-af57-480e-94b1-ea888dd1b1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([94, 94, 94]),\n",
       " array([24, 24, 24]),\n",
       " array([15, 15, 15]),\n",
       " array([0, 1, 2]))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    "    ).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8ae5c98c-2e1e-4b90-9cd8-9219e532fc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff[94,24,15,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e20f9b6f-72ad-4eaf-8c2e-045948a6179f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    ")[94,24,15,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "50930109-7282-4f7a-b9b8-be4347080f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(torch.sum(\n",
    "    cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    "    ),\n",
    "    axis=-1\n",
    ").detach().numpy()).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2c7b9ca2-b68b-423e-ba29-387f1223cf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([94]), array([24]), array([15]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(torch.sum(\n",
    "    cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    "    ),\n",
    "    axis=-1\n",
    ").detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c95f773d-cdde-440a-8b0f-92e5f7d93407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0332, 0.6706, 0.9716, 0.9757, 0.9757, 0.9757, 1.0741, 0.7729, 1.1290,\n",
       "        0.9757, 0.9757, 1.4398, 0.9554, 0.7639, 0.8608,    nan, 0.7205, 0.7551,\n",
       "        1.3197, 1.0787, 1.0720, 1.4066, 0.6798, 1.0329, 1.2583, 1.5059, 1.4623,\n",
       "        0.8676, 0.9757, 0.8594, 1.1232, 0.9757, 0.9757, 0.9757, 1.1720, 1.2588,\n",
       "        0.7667, 0.7437, 1.1948, 0.9847, 0.7845, 0.5300, 0.6469, 1.4376, 1.0879,\n",
       "        0.9078, 0.7355, 1.7366, 1.0102, 1.1947, 0.6780, 1.0162, 1.2185, 1.2742,\n",
       "        1.0918, 0.9757, 1.2834, 0.9914, 0.9757, 1.0105, 1.1534, 1.3210, 1.2183,\n",
       "        0.6016, 1.0976, 0.8873, 1.2643, 1.6309, 0.6532, 1.2003, 1.3970, 1.0385,\n",
       "        0.8668, 0.9967, 1.5562, 0.8305, 1.2290, 0.5932, 0.9200, 1.2263, 1.3277,\n",
       "        0.9840, 1.3741, 0.9757, 0.9794, 1.1538, 0.9106, 1.0421, 1.3159, 0.8671,\n",
       "        0.7996, 1.5560, 1.2296, 1.1848, 1.4853, 0.9757, 1.4080, 0.9757, 1.1681,\n",
       "        0.9757], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(\n",
    "    cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    "    ),\n",
    "    axis=-1\n",
    ")[94][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e8b9276e-d662-439a-9b61-e4601a77a29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98, 128, 100, 3])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.forward_conditionals[2:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b3442cad-93d6-4181-b590-a5d69354d056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Lt0_t1_loss = cat_diff.L_t0t1(Y_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8da26d15-6bcb-4458-ab25-1de1515e4d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1005, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lt0_t1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e29f0c8f-82d6-4f43-bf68-2e46840e5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ltminus1    = cat_diff.L_tminus1(Y_spins, noised_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d478c13f-58bb-4f5d-a8c8-3ad813a4c0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12800, 128])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.eval()\n",
    "\n",
    "t = ts.reshape(ts.shape[0] * ts.shape[1], 1)\n",
    "\n",
    "time_encoding = cat_diff.denoiser.forward_time_1(t)\n",
    "cat_diff.denoiser.forward_time_2(time_encoding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8d6daebf-99e6-42d5-8433-3fccc5d68420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  ..., 37.5615, 37.5615, 37.5615],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(time_encoding[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "dfe5f3b9-ea2a-4c93-964a-31ce0f11bb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ltminus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3fc83300-174d-4b94-ae57-f94084904032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noised_samples[1][3][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "faa4c9ab-ba8f-4ab6-a816-f799cc930644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cd5c0-d307-41c7-b29f-bbaa18cf2b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
