{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8605fcd-2201-40d2-850c-f7891db59663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from utils import *\n",
    "from architectures import *\n",
    "import preprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from CategoricalDiffusion import *\n",
    "from denoiser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d2efe8-6774-423d-8c03-725bb38e5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDenoiser(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_time,\n",
    "        d_time_hidden,\n",
    "        d_seq,\n",
    "        d_aas,\n",
    "        d_hidden = 128,\n",
    "        d_model = 128,\n",
    "        p = 0.1,\n",
    "        activation = torch.nn.ReLU(),\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = activation\n",
    "        self.p = p\n",
    "\n",
    "\n",
    "        self.forward_time_seq = FeedForward(d_seq*d_aas + d_time, d_model)\n",
    "\n",
    "        self.forward_time_seq_1 = FeedForward(d_model, d_model)\n",
    "        self.dropout_1 = torch.nn.Dropout(self.p)\n",
    "        \n",
    "        self.forward_time_seq_2 = FeedForward(d_model, d_model)\n",
    "        self.dropout_2 = torch.nn.Dropout(self.p)\n",
    "        \n",
    "        self.forward_time_seq_3 = FeedForward(d_model, d_model)\n",
    "        self.dropout_3 = torch.nn.Dropout(self.p)\n",
    "\n",
    "        self.feedforward_final = FeedForward(d_model, d_seq*d_aas)\n",
    "        \n",
    "    def forward(self, X, t):\n",
    "\n",
    "        time_points, batch_size, seq_length, aas = X.shape[0], X.shape[1], X.shape[2], X.shape[3]\n",
    "        \n",
    "        t = t.reshape(t.shape[0] * t.shape[1], 1)\n",
    "        X = X.view(time_points*batch_size, seq_length, aas)\n",
    "        \n",
    "        X_flattened = torch.nn.Flatten(start_dim=1)(X)\n",
    "        \n",
    "        seq_time_encoding = torch.concat([t, X_flattened], dim=-1)\n",
    "\n",
    "        input_encoding = self.forward_time_seq(seq_time_encoding)\n",
    "\n",
    "        X_1 = self.forward_time_seq_1(input_encoding)\n",
    "        X_1 = self.activation(X_1)\n",
    "        X_1 = self.dropout_1(X_1)\n",
    "\n",
    "        X_2 = self.forward_time_seq_2(X_1)\n",
    "        X_2 = self.activation(X_2)\n",
    "        X_2 = self.dropout_2(X_2)\n",
    "\n",
    "        X_3 = self.forward_time_seq_3(X_2)\n",
    "        X_3 = self.activation(X_3)\n",
    "        X_3 = self.dropout_3(X_3)\n",
    "\n",
    "        X_final = self.feedforward_final(X_3)\n",
    "\n",
    "        X_final = X_final.view(time_points, batch_size, seq_length, aas)\n",
    "        \n",
    "        Y_pred = torch.nn.Softmax(dim=-1)(X_final)\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4bd5823-7041-418a-884c-ca1031c065b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:19<00:00,  5.15it/s]\n"
     ]
    }
   ],
   "source": [
    "N_samples = 10000\n",
    "\n",
    "M = 2\n",
    "N_dim = 100\n",
    "\n",
    "bias = torch.zeros((N_dim,1))\n",
    "patterns = 2*torch.bernoulli(torch.ones((N_dim, M)) * 0.5) - 1\n",
    "\n",
    "spins = generate_data(patterns, bias, N_samples, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338d12d8-6a9c-4938-b139-ad7ff32d9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_spins = ((1+spins)/2).type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343ebac6-c349-47b7-9f36-cb87fe85cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_spin_vectors = torch.nn.functional.one_hot(index_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbef2da4-18fd-41ba-96d5-682267df6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinsDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    takes in one hot encoded spins X with one key - sequence, and Y with one, potentially two, keys - sequence and phenotype\n",
    "    inputs:\n",
    "        one_hot_spins: torch.Tensor representing spins (num_samples, dim, num_states)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 spins,\n",
    "                 include_mask = False,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.include_mask = include_mask\n",
    "        self.spins = spins\n",
    "        if self.include_mask:\n",
    "\n",
    "            self.spins = torch.cat((self.spins, torch.zeros((self.spins.shape[0], self.spins.shape[1], 1))), axis=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.spins.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = dict()\n",
    "        Y = dict()\n",
    "\n",
    "        Y['spins'] = self.spins[index]\n",
    "        X['spins'] = self.spins[index]\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb26dae-688f-4860-8fe9-7579105db651",
   "metadata": {},
   "outputs": [],
   "source": [
    "spins_dataset = SpinsDataset(one_hot_spin_vectors, include_mask=True)\n",
    "spins_loader = torch.utils.data.DataLoader(spins_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e2131f-2ef3-4641-9512-9879531ea990",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in spins_loader:\n",
    "    X, Y = batch\n",
    "    X_spins = X['spins']\n",
    "    Y_spins = Y['spins']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dde4ff0-281f-4261-a652-ddfce207a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_matrix = Noiser(noiser = 'BERT-LIKE', beta_t = 0.01, k=2).noise_matrix\n",
    "ts, noised_samples = noiser(X_spins, noise_matrix, 100, X_spins.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da49505-e103-4358-a5fa-c6d25dcebf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 16, 100, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noised_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "870d0c2e-9c0a-4dde-94bd-1723fc49f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser = MLPDenoiser(1,128,X_spins.shape[1],X_spins.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e629ef5-cd83-4c94-a39d-d13b732ee454",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = denoiser(noised_samples, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba245476-2b92-45a9-95f8-784a0bd19782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 16, 100, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c09044ac-3020-4f2f-97fb-bb1879103717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 16, 100, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noised_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339adbcf-0aa8-4aef-ac80-ca48268d1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_diff = CategoricalDiffusion(denoiser, noise_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6850e5a5-004e-4a27-bee1-d7941afa080f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3370, 0.3315, 0.3315],\n",
       "          [0.3478, 0.3261, 0.3261],\n",
       "          [0.3243, 0.3513, 0.3243],\n",
       "          ...,\n",
       "          [0.3267, 0.3267, 0.3466],\n",
       "          [0.3190, 0.3315, 0.3495],\n",
       "          [0.3420, 0.3355, 0.3226]],\n",
       "\n",
       "         [[0.3403, 0.3299, 0.3299],\n",
       "          [0.3494, 0.3253, 0.3253],\n",
       "          [0.3217, 0.3539, 0.3244],\n",
       "          ...,\n",
       "          [0.3279, 0.3279, 0.3441],\n",
       "          [0.3178, 0.3367, 0.3455],\n",
       "          [0.3429, 0.3342, 0.3229]],\n",
       "\n",
       "         [[0.3376, 0.3312, 0.3312],\n",
       "          [0.3412, 0.3294, 0.3294],\n",
       "          [0.3239, 0.3523, 0.3239],\n",
       "          ...,\n",
       "          [0.3274, 0.3274, 0.3452],\n",
       "          [0.3275, 0.3239, 0.3486],\n",
       "          [0.3471, 0.3301, 0.3228]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.3350, 0.3325, 0.3325],\n",
       "          [0.3467, 0.3267, 0.3267],\n",
       "          [0.3216, 0.3490, 0.3294],\n",
       "          ...,\n",
       "          [0.3270, 0.3270, 0.3460],\n",
       "          [0.3281, 0.3317, 0.3402],\n",
       "          [0.3436, 0.3315, 0.3249]],\n",
       "\n",
       "         [[0.3414, 0.3293, 0.3293],\n",
       "          [0.3444, 0.3278, 0.3278],\n",
       "          [0.3239, 0.3521, 0.3239],\n",
       "          ...,\n",
       "          [0.3248, 0.3248, 0.3504],\n",
       "          [0.3225, 0.3298, 0.3477],\n",
       "          [0.3436, 0.3316, 0.3247]],\n",
       "\n",
       "         [[0.3397, 0.3301, 0.3301],\n",
       "          [0.3418, 0.3291, 0.3291],\n",
       "          [0.3203, 0.3520, 0.3277],\n",
       "          ...,\n",
       "          [0.3251, 0.3251, 0.3497],\n",
       "          [0.3206, 0.3340, 0.3455],\n",
       "          [0.3435, 0.3296, 0.3269]]],\n",
       "\n",
       "\n",
       "        [[[0.3377, 0.3312, 0.3312],\n",
       "          [0.3439, 0.3281, 0.3281],\n",
       "          [0.3221, 0.3508, 0.3270],\n",
       "          ...,\n",
       "          [0.3259, 0.3259, 0.3482],\n",
       "          [0.3187, 0.3305, 0.3508],\n",
       "          [0.3442, 0.3334, 0.3224]],\n",
       "\n",
       "         [[0.3335, 0.3333, 0.3333],\n",
       "          [0.3490, 0.3255, 0.3255],\n",
       "          [0.3241, 0.3516, 0.3243],\n",
       "          ...,\n",
       "          [0.3265, 0.3265, 0.3470],\n",
       "          [0.3288, 0.3250, 0.3462],\n",
       "          [0.3488, 0.3269, 0.3242]],\n",
       "\n",
       "         [[0.3416, 0.3292, 0.3292],\n",
       "          [0.3447, 0.3276, 0.3276],\n",
       "          [0.3216, 0.3522, 0.3262],\n",
       "          ...,\n",
       "          [0.3260, 0.3260, 0.3481],\n",
       "          [0.3215, 0.3334, 0.3451],\n",
       "          [0.3437, 0.3345, 0.3218]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.3406, 0.3297, 0.3297],\n",
       "          [0.3420, 0.3290, 0.3290],\n",
       "          [0.3238, 0.3479, 0.3283],\n",
       "          ...,\n",
       "          [0.3262, 0.3262, 0.3476],\n",
       "          [0.3200, 0.3289, 0.3511],\n",
       "          [0.3474, 0.3286, 0.3240]],\n",
       "\n",
       "         [[0.3360, 0.3320, 0.3320],\n",
       "          [0.3440, 0.3280, 0.3280],\n",
       "          [0.3230, 0.3521, 0.3249],\n",
       "          ...,\n",
       "          [0.3276, 0.3276, 0.3449],\n",
       "          [0.3156, 0.3327, 0.3517],\n",
       "          [0.3435, 0.3331, 0.3233]],\n",
       "\n",
       "         [[0.3410, 0.3295, 0.3295],\n",
       "          [0.3443, 0.3278, 0.3278],\n",
       "          [0.3262, 0.3477, 0.3262],\n",
       "          ...,\n",
       "          [0.3279, 0.3279, 0.3442],\n",
       "          [0.3169, 0.3274, 0.3557],\n",
       "          [0.3453, 0.3301, 0.3246]]],\n",
       "\n",
       "\n",
       "        [[[0.3365, 0.3318, 0.3318],\n",
       "          [0.3410, 0.3295, 0.3295],\n",
       "          [0.3246, 0.3508, 0.3246],\n",
       "          ...,\n",
       "          [0.3256, 0.3256, 0.3489],\n",
       "          [0.3185, 0.3306, 0.3510],\n",
       "          [0.3399, 0.3356, 0.3245]],\n",
       "\n",
       "         [[0.3374, 0.3313, 0.3313],\n",
       "          [0.3405, 0.3297, 0.3297],\n",
       "          [0.3258, 0.3483, 0.3258],\n",
       "          ...,\n",
       "          [0.3270, 0.3270, 0.3459],\n",
       "          [0.3232, 0.3260, 0.3507],\n",
       "          [0.3449, 0.3286, 0.3265]],\n",
       "\n",
       "         [[0.3403, 0.3299, 0.3299],\n",
       "          [0.3377, 0.3312, 0.3312],\n",
       "          [0.3245, 0.3454, 0.3302],\n",
       "          ...,\n",
       "          [0.3226, 0.3226, 0.3547],\n",
       "          [0.3229, 0.3310, 0.3461],\n",
       "          [0.3481, 0.3261, 0.3258]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.3369, 0.3315, 0.3315],\n",
       "          [0.3424, 0.3288, 0.3288],\n",
       "          [0.3234, 0.3451, 0.3315],\n",
       "          ...,\n",
       "          [0.3265, 0.3265, 0.3471],\n",
       "          [0.3142, 0.3364, 0.3493],\n",
       "          [0.3450, 0.3365, 0.3184]],\n",
       "\n",
       "         [[0.3333, 0.3333, 0.3333],\n",
       "          [0.3408, 0.3296, 0.3296],\n",
       "          [0.3206, 0.3540, 0.3254],\n",
       "          ...,\n",
       "          [0.3260, 0.3260, 0.3480],\n",
       "          [0.3217, 0.3274, 0.3508],\n",
       "          [0.3436, 0.3309, 0.3255]],\n",
       "\n",
       "         [[0.3427, 0.3286, 0.3286],\n",
       "          [0.3450, 0.3275, 0.3275],\n",
       "          [0.3246, 0.3507, 0.3246],\n",
       "          ...,\n",
       "          [0.3265, 0.3265, 0.3469],\n",
       "          [0.3236, 0.3268, 0.3496],\n",
       "          [0.3461, 0.3275, 0.3264]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.3313, 0.3373, 0.3313],\n",
       "          [0.3333, 0.3333, 0.3333],\n",
       "          [0.3024, 0.3521, 0.3455],\n",
       "          ...,\n",
       "          [0.3079, 0.3161, 0.3761],\n",
       "          [0.3420, 0.3430, 0.3150],\n",
       "          [0.3545, 0.3253, 0.3201]],\n",
       "\n",
       "         [[0.3309, 0.3382, 0.3309],\n",
       "          [0.3402, 0.3299, 0.3299],\n",
       "          [0.3112, 0.3701, 0.3186],\n",
       "          ...,\n",
       "          [0.3095, 0.3369, 0.3535],\n",
       "          [0.3349, 0.3399, 0.3252],\n",
       "          [0.3473, 0.3382, 0.3145]],\n",
       "\n",
       "         [[0.3284, 0.3432, 0.3284],\n",
       "          [0.3333, 0.3333, 0.3333],\n",
       "          [0.3151, 0.3333, 0.3515],\n",
       "          ...,\n",
       "          [0.3129, 0.3225, 0.3646],\n",
       "          [0.3090, 0.3514, 0.3396],\n",
       "          [0.3432, 0.3513, 0.3054]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.3318, 0.3364, 0.3318],\n",
       "          [0.3450, 0.3275, 0.3275],\n",
       "          [0.3094, 0.3813, 0.3094],\n",
       "          ...,\n",
       "          [0.3413, 0.3178, 0.3409],\n",
       "          [0.3436, 0.3168, 0.3396],\n",
       "          [0.3607, 0.3233, 0.3159]],\n",
       "\n",
       "         [[0.3333, 0.3333, 0.3333],\n",
       "          [0.3345, 0.3327, 0.3327],\n",
       "          [0.3223, 0.3555, 0.3223],\n",
       "          ...,\n",
       "          [0.3048, 0.3441, 0.3511],\n",
       "          [0.3092, 0.3551, 0.3357],\n",
       "          [0.3304, 0.3530, 0.3166]],\n",
       "\n",
       "         [[0.3285, 0.3430, 0.3285],\n",
       "          [0.3368, 0.3316, 0.3316],\n",
       "          [0.3148, 0.3650, 0.3202],\n",
       "          ...,\n",
       "          [0.3198, 0.3198, 0.3604],\n",
       "          [0.3300, 0.3484, 0.3216],\n",
       "          [0.3518, 0.3379, 0.3103]]],\n",
       "\n",
       "\n",
       "        [[[0.3280, 0.3440, 0.3280],\n",
       "          [0.3333, 0.3333, 0.3333],\n",
       "          [0.2969, 0.3623, 0.3409],\n",
       "          ...,\n",
       "          [0.3038, 0.3344, 0.3618],\n",
       "          [0.3362, 0.3205, 0.3433],\n",
       "          [0.3487, 0.3346, 0.3167]],\n",
       "\n",
       "         [[0.3366, 0.3317, 0.3317],\n",
       "          [0.3353, 0.3323, 0.3323],\n",
       "          [0.3064, 0.3672, 0.3264],\n",
       "          ...,\n",
       "          [0.3182, 0.3182, 0.3636],\n",
       "          [0.3256, 0.3541, 0.3202],\n",
       "          [0.3521, 0.3295, 0.3183]],\n",
       "\n",
       "         [[0.3265, 0.3470, 0.3265],\n",
       "          [0.3355, 0.3323, 0.3323],\n",
       "          [0.3089, 0.3538, 0.3373],\n",
       "          ...,\n",
       "          [0.3124, 0.3246, 0.3630],\n",
       "          [0.3402, 0.3355, 0.3243],\n",
       "          [0.3437, 0.3442, 0.3121]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.3349, 0.3395, 0.3256],\n",
       "          [0.3333, 0.3333, 0.3333],\n",
       "          [0.3084, 0.3751, 0.3165],\n",
       "          ...,\n",
       "          [0.3138, 0.3138, 0.3724],\n",
       "          [0.3465, 0.3192, 0.3342],\n",
       "          [0.3578, 0.3211, 0.3211]],\n",
       "\n",
       "         [[0.3333, 0.3333, 0.3333],\n",
       "          [0.3333, 0.3333, 0.3333],\n",
       "          [0.3180, 0.3583, 0.3237],\n",
       "          ...,\n",
       "          [0.3200, 0.3200, 0.3599],\n",
       "          [0.3330, 0.3170, 0.3499],\n",
       "          [0.3568, 0.3348, 0.3084]],\n",
       "\n",
       "         [[0.3333, 0.3333, 0.3333],\n",
       "          [0.3366, 0.3317, 0.3317],\n",
       "          [0.3222, 0.3458, 0.3320],\n",
       "          ...,\n",
       "          [0.3136, 0.3218, 0.3645],\n",
       "          [0.3147, 0.3360, 0.3493],\n",
       "          [0.3336, 0.3457, 0.3207]]],\n",
       "\n",
       "\n",
       "        [[[0.3279, 0.3442, 0.3279],\n",
       "          [0.3422, 0.3289, 0.3289],\n",
       "          [0.3071, 0.3853, 0.3077],\n",
       "          ...,\n",
       "          [0.3141, 0.3201, 0.3658],\n",
       "          [0.3324, 0.3384, 0.3292],\n",
       "          [0.3309, 0.3484, 0.3207]],\n",
       "\n",
       "         [[0.3209, 0.3582, 0.3209],\n",
       "          [0.3406, 0.3297, 0.3297],\n",
       "          [0.3134, 0.3504, 0.3362],\n",
       "          ...,\n",
       "          [0.3189, 0.3232, 0.3579],\n",
       "          [0.3292, 0.3574, 0.3133],\n",
       "          [0.3385, 0.3492, 0.3123]],\n",
       "\n",
       "         [[0.3255, 0.3490, 0.3255],\n",
       "          [0.3361, 0.3319, 0.3319],\n",
       "          [0.2993, 0.3632, 0.3375],\n",
       "          ...,\n",
       "          [0.3136, 0.3153, 0.3712],\n",
       "          [0.3487, 0.3225, 0.3287],\n",
       "          [0.3536, 0.3313, 0.3151]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.3304, 0.3393, 0.3304],\n",
       "          [0.3333, 0.3333, 0.3333],\n",
       "          [0.3163, 0.3610, 0.3226],\n",
       "          ...,\n",
       "          [0.3080, 0.3320, 0.3600],\n",
       "          [0.3219, 0.3414, 0.3367],\n",
       "          [0.3239, 0.3629, 0.3131]],\n",
       "\n",
       "         [[0.3329, 0.3342, 0.3329],\n",
       "          [0.3333, 0.3333, 0.3333],\n",
       "          [0.3140, 0.3719, 0.3140],\n",
       "          ...,\n",
       "          [0.3152, 0.3171, 0.3677],\n",
       "          [0.3370, 0.3251, 0.3379],\n",
       "          [0.3400, 0.3300, 0.3300]],\n",
       "\n",
       "         [[0.3333, 0.3333, 0.3333],\n",
       "          [0.3427, 0.3287, 0.3287],\n",
       "          [0.3195, 0.3288, 0.3517],\n",
       "          ...,\n",
       "          [0.3092, 0.3265, 0.3644],\n",
       "          [0.3375, 0.3225, 0.3400],\n",
       "          [0.3311, 0.3495, 0.3194]]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.denoiser(noised_samples,ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf16e13e-5d3f-4d3d-b83e-b03c0479c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_diff.decode(noised_samples, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "387b0b87-145d-421b-aacf-ed0663cf7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_diff.calc_forward_conditionals(noised_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b995d8c-deb5-4c07-8875-90cb5cb11d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7237)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.L_T(noised_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10b85ca4-7af3-4c28-9bbc-144de8074c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0975, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.L_t0t1(Y_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d012cfb4-6e45-4b37-bd14-87edd961fd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8218, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.L_tminus1(Y_spins, noised_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed3a9a-e00a-4a16-afd4-3ffd52296b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                        | 1/100 [00:45<1:15:17, 45.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 0 is 135.84732270240784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                        | 2/100 [01:30<1:13:32, 45.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 1 is 121.05670738220215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                       | 3/100 [02:15<1:13:07, 45.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 2 is 111.6009372472763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                       | 4/100 [03:00<1:11:47, 44.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 3 is 105.38810896873474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                       | 5/100 [03:43<1:10:22, 44.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 4 is 103.57412123680115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                      | 6/100 [04:27<1:09:31, 44.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 5 is 102.41586709022522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                      | 7/100 [05:15<1:10:11, 45.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 6 is 101.82431697845459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                     | 8/100 [06:12<1:15:13, 49.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 7 is 101.42035746574402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▋                                     | 9/100 [07:12<1:19:31, 52.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 8 is 100.73042058944702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 10/100 [08:13<1:22:36, 55.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 9 is 100.37978506088257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▍                                   | 11/100 [09:09<1:22:24, 55.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 10 is 99.91097223758698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▊                                   | 12/100 [10:05<1:21:24, 55.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 11 is 99.74670684337616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▏                                  | 13/100 [11:02<1:21:18, 56.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 12 is 99.48744630813599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▌                                  | 14/100 [11:59<1:20:42, 56.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 13 is 99.3787248134613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████                                  | 15/100 [12:55<1:19:53, 56.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 14 is 99.16166853904724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▍                                 | 16/100 [13:52<1:19:10, 56.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 15 is 98.85555231571198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▊                                 | 17/100 [14:49<1:18:10, 56.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 16 is 98.83682644367218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▏                                | 18/100 [15:45<1:17:07, 56.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 17 is 98.70484399795532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▌                                | 19/100 [16:40<1:15:28, 55.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 18 is 98.6557366847992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████                                | 20/100 [17:36<1:14:42, 56.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 19 is 98.4665961265564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▍                               | 21/100 [18:34<1:14:35, 56.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 20 is 98.3373372554779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▊                               | 22/100 [19:32<1:13:58, 56.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 21 is 98.27106475830078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▏                              | 23/100 [20:30<1:13:25, 57.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 22 is 98.34451687335968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▌                              | 24/100 [21:26<1:11:59, 56.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 23 is 98.09732925891876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████                              | 25/100 [22:19<1:09:43, 55.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 24 is 98.00088608264923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████▍                             | 26/100 [23:14<1:08:27, 55.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 25 is 97.8824177980423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▊                             | 27/100 [24:10<1:07:55, 55.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 26 is 97.8516857624054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████▏                            | 28/100 [25:06<1:07:06, 55.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 27 is 97.75183618068695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▌                            | 29/100 [26:02<1:05:52, 55.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 28 is 97.62625348567963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████                            | 30/100 [26:57<1:04:48, 55.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 29 is 97.49396598339081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████▍                           | 31/100 [27:50<1:03:13, 54.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 30 is 97.53072082996368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▊                           | 32/100 [28:45<1:02:03, 54.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 31 is 97.50134766101837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▏                          | 33/100 [29:38<1:00:49, 54.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 32 is 97.42038226127625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████▌                          | 34/100 [30:34<1:00:24, 54.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 33 is 97.31864750385284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████▌                       | 35/100 [1:01:50<10:51:09, 601.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 34 is 97.31011879444122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████▉                       | 36/100 [1:27:40<15:44:52, 885.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 35 is 97.20506167411804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████▉                      | 37/100 [1:58:21<20:30:57, 1172.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 36 is 97.08378505706787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████▋                      | 38/100 [2:00:17<14:43:55, 855.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 37 is 97.07422626018524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████                      | 39/100 [2:18:39<15:44:48, 929.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 38 is 96.98706912994385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████                     | 40/100 [2:38:15<16:43:27, 1003.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 39 is 97.00689280033112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████▊                     | 41/100 [2:39:40<11:55:52, 728.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 40 is 96.92144405841827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████▌                     | 42/100 [2:40:53<8:33:41, 531.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 41 is 96.88095653057098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████▉                     | 43/100 [2:42:13<6:16:15, 396.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 42 is 96.84663331508636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████▎                    | 44/100 [3:00:04<9:18:32, 598.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 43 is 96.79241728782654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████▋                    | 45/100 [3:01:25<6:46:14, 443.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 44 is 96.72847485542297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████                    | 46/100 [3:02:42<5:00:07, 333.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 45 is 96.65947902202606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████▍                   | 47/100 [3:04:04<3:47:50, 257.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 46 is 96.65366506576538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████▊                   | 48/100 [3:05:31<2:59:09, 206.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 47 is 96.59584629535675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████▏                  | 49/100 [3:06:52<2:23:32, 168.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 48 is 96.59914898872375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████▌                  | 50/100 [3:08:18<2:00:06, 144.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 49 is 96.57844698429108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████▊                  | 51/100 [3:09:45<1:43:32, 126.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 50 is 96.50876569747925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████▏                 | 52/100 [3:11:12<1:31:56, 114.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 51 is 96.4804699420929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████▌                 | 53/100 [3:12:37<1:23:06, 106.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 52 is 96.41776490211487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████▉                 | 54/100 [3:14:04<1:16:57, 100.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 53 is 96.35691034793854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████▉                 | 55/100 [3:15:36<1:13:19, 97.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 54 is 96.35047352313995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████▎                | 56/100 [3:17:07<1:10:05, 95.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 55 is 96.31885266304016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████▋                | 57/100 [3:18:40<1:08:00, 94.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 56 is 96.33619499206543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████                | 58/100 [3:20:10<1:05:31, 93.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 57 is 96.31549298763275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████▍               | 59/100 [3:21:41<1:03:21, 92.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 58 is 96.28060913085938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▊               | 60/100 [3:23:09<1:00:52, 91.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 59 is 92.02845573425293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████▍               | 61/100 [3:24:38<58:51, 90.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 60 is 86.50207257270813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████▊               | 62/100 [3:26:12<58:03, 91.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 61 is 83.93247842788696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████▏              | 63/100 [3:27:41<55:59, 90.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 62 is 83.21084862947464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████▌              | 64/100 [3:29:07<53:39, 89.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 63 is 82.41088318824768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████              | 65/100 [3:30:32<51:25, 88.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 64 is 82.29489922523499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████▍             | 66/100 [3:31:21<43:14, 76.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 65 is 81.89134383201599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████▍          | 67/100 [13:46:16<101:57:02, 11121.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 66 is 81.2218416929245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████           | 68/100 [14:26:10<75:35:09, 8503.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 67 is 80.85507422685623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████▍          | 69/100 [15:19:47<59:34:07, 6917.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 68 is 80.58616369962692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████▊          | 70/100 [15:20:33<40:28:03, 4856.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 69 is 80.15747720003128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████▏         | 71/100 [15:28:55<28:35:44, 3549.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 70 is 79.81055492162704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████▍         | 72/100 [15:30:35<19:33:37, 2514.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 71 is 79.28730779886246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████▊         | 73/100 [15:31:23<13:18:39, 1774.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 72 is 79.12084889411926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████▉         | 74/100 [15:32:09<9:04:23, 1256.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 73 is 78.83034461736679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████         | 75/100 [15:32:55<6:12:09, 893.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 74 is 78.51904970407486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████▎        | 76/100 [15:33:37<4:15:09, 637.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 75 is 78.29425460100174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████▋        | 77/100 [15:34:21<2:56:08, 459.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 76 is 78.08866488933563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████        | 78/100 [15:35:06<2:02:55, 335.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 77 is 78.01650094985962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████▍       | 79/100 [15:35:52<1:27:00, 248.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 78 is 77.84435653686523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████▊       | 80/100 [15:36:35<1:02:19, 186.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 79 is 77.63565111160278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████▊       | 81/100 [15:37:20<45:38, 144.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 80 is 77.67585772275925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████▏      | 82/100 [15:38:04<34:17, 114.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 81 is 77.34525293111801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████▎      | 83/100 [15:38:49<26:29, 93.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 82 is 77.02098935842514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████▊      | 84/100 [15:39:33<20:59, 78.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 83 is 77.31703680753708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████▏     | 85/100 [15:40:19<17:08, 68.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 84 is 77.15096467733383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████▌     | 86/100 [15:41:03<14:17, 61.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 85 is 77.17066425085068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████▉     | 87/100 [15:41:47<12:10, 56.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 86 is 76.77328258752823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████▎    | 88/100 [15:42:33<10:36, 53.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 87 is 76.7115079164505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████▋    | 89/100 [15:43:16<09:11, 50.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 88 is 76.94848650693893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████    | 90/100 [15:44:00<08:02, 48.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 89 is 76.72017842531204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████▍   | 91/100 [15:44:43<07:00, 46.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 90 is 76.74418246746063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████▉   | 92/100 [15:45:27<06:05, 45.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 91 is 76.71150887012482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████▎  | 93/100 [15:46:12<05:18, 45.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 92 is 76.60798090696335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████▋  | 94/100 [15:46:56<04:31, 45.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall loss at epoch 93 is 76.48578530550003\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 100\n",
    "\n",
    "denoiser = MLPDenoiser(1,128,X_spins.shape[1],X_spins.shape[2], p=0.9, activation = torch.nn.Tanh())\n",
    "cat_diff = CategoricalDiffusion(denoiser, noise_matrix)\n",
    "\n",
    "cat_diff.train()\n",
    "optim = torch.optim.Adam(cat_diff.parameters(), lr = 1e-3)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    overall_loss = 0\n",
    "    spins_loader = torch.utils.data.DataLoader(spins_dataset, batch_size=128, shuffle=True)\n",
    "    for batch in spins_loader:\n",
    "        X, Y = batch\n",
    "        \n",
    "        X_spins = X['spins']\n",
    "        Y_spins = Y['spins']\n",
    "        \n",
    "        ts, noised_samples = noiser(X_spins, noise_matrix, 100, X_spins.shape[-1])\n",
    "\n",
    "        cat_diff.decode(noised_samples, ts)\n",
    "        cat_diff.calc_forward_conditionals(noised_samples)\n",
    "        \n",
    "        LT_loss     = cat_diff.L_T(noised_samples)\n",
    "        \n",
    "        Lt0_t1_loss = cat_diff.L_t0t1(Y_spins)\n",
    "\n",
    "\n",
    "        Ltminus1    = cat_diff.L_tminus1(Y_spins, noised_samples)\n",
    "\n",
    "\n",
    "        loss = Lt0_t1_loss + Ltminus1\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_value_(cat_diff.parameters(), 0.1)\n",
    "\n",
    "        optim.step()\n",
    "        #print(loss.item())\n",
    "        overall_loss += loss.item()\n",
    "\n",
    "    print('overall loss at epoch {} is '.format(epoch) + str(overall_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fa328e5d-b3e9-471a-89da-50d37c0f2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = cat_diff.one_step_reverse_conditional(Y_spins, noised_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "aa3087fe-78d5-4e0f-9821-b31868ce01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_xtminus1_xt_giv_x0 = cat_diff.q_xtminus1_xt_giv_x0(noised_samples, stuff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "03da8669-1401-4c0d-9f75-6836e4eba60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = cat_diff.y_pred[2:]\n",
    "\n",
    "px_tminus1_giv_xt = q_xtminus1_xt_giv_x0 * denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3b0281aa-033a-48f7-b36e-e66f753d6818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000e+00, 3.1462e-01, 0.0000e+00],\n",
       "          [3.5677e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.3245e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.2670e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0302e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 2.9244e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.3716e-01, 0.0000e+00],\n",
       "          [3.2219e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [2.9704e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.2619e-01, 0.0000e+00],\n",
       "          [3.6161e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [2.8870e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.0515e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.1967e-01, 0.0000e+00],\n",
       "          [3.1448e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.8615e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0698e-01, 0.0000e+00],\n",
       "          [3.2339e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 1.5856e-01, 3.2519e-03],\n",
       "          [3.3326e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2670e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.3106e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2086e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.1995e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.2948e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3625e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2670e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.8064e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0472e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2592e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.2670e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.6159e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.4483e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.4310e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.5662e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.2670e-01, 0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 3.3722e-01, 0.0000e+00],\n",
       "          [3.1850e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.4382e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.2148e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.4507e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3020e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.0407e-01, 0.0000e+00],\n",
       "          [3.6837e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.2343e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.2343e-01, 0.0000e+00],\n",
       "          [3.3788e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.4038e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.4823e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0180e-01, 0.0000e+00],\n",
       "          [3.3380e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.2256e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2715e-01, 0.0000e+00],\n",
       "          [3.0749e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 8.7965e-02, 5.4671e-03],\n",
       "          [3.1709e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2343e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.1614e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 2.6522e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 2.9581e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.1504e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0370e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2343e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.1425e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0266e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 1.1164e-01, 6.4808e-03]],\n",
       "\n",
       "         [[3.5002e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.1669e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3298e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.2343e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0823e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0815e-01, 0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 3.3066e-01, 0.0000e+00],\n",
       "          [3.3928e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0747e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.8212e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0885e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.6789e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 2.9206e-01, 0.0000e+00],\n",
       "          [3.2165e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.3117e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.1823e-01, 0.0000e+00],\n",
       "          [3.3278e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.1436e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 3.2958e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2058e-01, 0.0000e+00],\n",
       "          [3.1537e-01, 0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.6215e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3315e-01, 0.0000e+00],\n",
       "          [3.2449e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 7.6083e-02, 1.0498e-02],\n",
       "          [2.9603e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 2.9741e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.2020e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2264e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3696e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.1637e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.2020e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.0711e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.1888e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.2946e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 8.7624e-02, 9.3493e-03]],\n",
       "\n",
       "         [[3.4573e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [3.4582e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.1756e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.4381e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [7.8847e-02, 0.0000e+00, 9.9003e-03],\n",
       "          [2.8895e-01, 0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 3.7909e-04, 4.1565e-01],\n",
       "          [1.1423e-03, 0.0000e+00, 2.2191e-01],\n",
       "          [5.8507e-04, 0.0000e+00, 1.2066e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.7304e-04, 3.0467e-01],\n",
       "          [0.0000e+00, 4.0612e-04, 4.0841e-01],\n",
       "          [0.0000e+00, 7.6940e-04, 2.0632e-01]],\n",
       "\n",
       "         [[0.0000e+00, 5.3297e-04, 2.4242e-01],\n",
       "          [7.2225e-04, 0.0000e+00, 2.2855e-01],\n",
       "          [7.6940e-04, 0.0000e+00, 2.0632e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 7.6940e-04, 2.0632e-01],\n",
       "          [7.6297e-04, 0.0000e+00, 2.0976e-01],\n",
       "          [6.2826e-04, 0.0000e+00, 2.3843e-01]],\n",
       "\n",
       "         [[0.0000e+00, 6.9511e-04, 1.8640e-01],\n",
       "          [0.0000e+00, 4.6922e-04, 3.6730e-01],\n",
       "          [7.6940e-04, 0.0000e+00, 2.0632e-01],\n",
       "          ...,\n",
       "          [5.9710e-04, 0.0000e+00, 2.9872e-01],\n",
       "          [0.0000e+00, 5.9034e-04, 3.0234e-01],\n",
       "          [5.8848e-04, 0.0000e+00, 3.0334e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 6.6684e-04, 1.9659e-01],\n",
       "          [7.5912e-04, 0.0000e+00, 2.1183e-01],\n",
       "          [0.0000e+00, 7.7719e-04, 2.0527e-01],\n",
       "          ...,\n",
       "          [7.4850e-04, 0.0000e+00, 2.1752e-01],\n",
       "          [0.0000e+00, 7.0018e-04, 1.8250e-01],\n",
       "          [0.0000e+00, 7.6940e-04, 2.0632e-01]],\n",
       "\n",
       "         [[6.1240e-04, 0.0000e+00, 2.9052e-01],\n",
       "          [0.0000e+00, 1.0043e-03, 2.1995e-01],\n",
       "          [0.0000e+00, 6.5847e-04, 2.6581e-01],\n",
       "          ...,\n",
       "          [5.5107e-04, 0.0000e+00, 3.2341e-01],\n",
       "          [5.1028e-04, 0.0000e+00, 3.4528e-01],\n",
       "          [0.0000e+00, 8.2352e-04, 1.9133e-01]],\n",
       "\n",
       "         [[9.9928e-04, 0.0000e+00, 1.7550e-01],\n",
       "          [5.6144e-04, 0.0000e+00, 3.1785e-01],\n",
       "          [0.0000e+00, 6.8461e-04, 2.1139e-01],\n",
       "          ...,\n",
       "          [8.1555e-04, 0.0000e+00, 1.5929e-01],\n",
       "          [7.4270e-04, 0.0000e+00, 2.2063e-01],\n",
       "          [6.8001e-04, 0.0000e+00, 2.5426e-01]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 6.2419e-04, 2.7702e-01],\n",
       "          [6.2415e-04, 0.0000e+00, 2.3417e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 7.4954e-04, 2.0759e-01],\n",
       "          [0.0000e+00, 4.9372e-04, 1.6831e-01],\n",
       "          [0.0000e+00, 7.4954e-04, 2.0759e-01]],\n",
       "\n",
       "         [[0.0000e+00, 6.7042e-04, 1.7931e-01],\n",
       "          [8.1981e-04, 0.0000e+00, 2.1633e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 7.3227e-04, 2.2773e-01],\n",
       "          [8.1097e-04, 0.0000e+00, 1.9908e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01]],\n",
       "\n",
       "         [[0.0000e+00, 7.2805e-04, 2.0163e-01],\n",
       "          [0.0000e+00, 7.3321e-04, 2.0630e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          ...,\n",
       "          [7.4690e-04, 0.0000e+00, 2.0905e-01],\n",
       "          [0.0000e+00, 7.3979e-04, 2.0055e-01],\n",
       "          [7.6551e-04, 0.0000e+00, 2.0245e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 7.4153e-04, 2.0537e-01],\n",
       "          [7.9015e-04, 0.0000e+00, 1.9154e-01],\n",
       "          [0.0000e+00, 7.2907e-04, 2.1708e-01],\n",
       "          ...,\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          [0.0000e+00, 7.2993e-04, 2.0216e-01],\n",
       "          [0.0000e+00, 7.7022e-04, 1.9826e-01]],\n",
       "\n",
       "         [[7.5745e-04, 0.0000e+00, 2.3313e-01],\n",
       "          [0.0000e+00, 6.9705e-04, 2.3667e-01],\n",
       "          [0.0000e+00, 7.2789e-04, 2.0094e-01],\n",
       "          ...,\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          [1.0090e-03, 0.0000e+00, 1.7166e-01],\n",
       "          [0.0000e+00, 7.1179e-04, 2.2850e-01]],\n",
       "\n",
       "         [[7.4954e-04, 0.0000e+00, 2.0759e-01],\n",
       "          [6.9930e-04, 0.0000e+00, 2.3542e-01],\n",
       "          [0.0000e+00, 6.7917e-04, 2.3259e-01],\n",
       "          ...,\n",
       "          [7.6032e-04, 0.0000e+00, 2.0610e-01],\n",
       "          [8.4695e-04, 0.0000e+00, 2.0037e-01],\n",
       "          [7.4954e-04, 0.0000e+00, 2.0759e-01]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 7.3587e-04, 1.9927e-01],\n",
       "          [7.1227e-04, 0.0000e+00, 2.0369e-01],\n",
       "          [7.3028e-04, 0.0000e+00, 2.0885e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 6.9042e-04, 2.3164e-01],\n",
       "          [0.0000e+00, 7.0599e-04, 2.2274e-01],\n",
       "          [0.0000e+00, 7.0283e-04, 2.1575e-01]],\n",
       "\n",
       "         [[0.0000e+00, 7.5273e-04, 1.9288e-01],\n",
       "          [7.3204e-04, 0.0000e+00, 2.2124e-01],\n",
       "          [7.3028e-04, 0.0000e+00, 2.0885e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 7.4048e-04, 2.1745e-01],\n",
       "          [8.1192e-04, 0.0000e+00, 1.9717e-01],\n",
       "          [8.4004e-04, 0.0000e+00, 1.9564e-01]],\n",
       "\n",
       "         [[0.0000e+00, 7.3111e-04, 1.6817e-01],\n",
       "          [0.0000e+00, 6.2841e-04, 2.6711e-01],\n",
       "          [8.2073e-04, 0.0000e+00, 2.3377e-01],\n",
       "          ...,\n",
       "          [7.5608e-04, 0.0000e+00, 2.0516e-01],\n",
       "          [0.0000e+00, 6.2543e-04, 1.7886e-01],\n",
       "          [7.7498e-04, 0.0000e+00, 2.0334e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 1.0958e-03, 1.5658e-01],\n",
       "          [5.5401e-04, 0.0000e+00, 2.2553e-01],\n",
       "          [0.0000e+00, 6.7116e-04, 1.7928e-01],\n",
       "          ...,\n",
       "          [5.4571e-04, 0.0000e+00, 3.1441e-01],\n",
       "          [0.0000e+00, 7.2986e-04, 2.0908e-01],\n",
       "          [0.0000e+00, 7.3028e-04, 2.0885e-01]],\n",
       "\n",
       "         [[7.9693e-04, 0.0000e+00, 1.7161e-01],\n",
       "          [0.0000e+00, 6.9062e-04, 1.9751e-01],\n",
       "          [0.0000e+00, 4.5239e-04, 1.5962e-01],\n",
       "          ...,\n",
       "          [7.3028e-04, 0.0000e+00, 2.0885e-01],\n",
       "          [9.1702e-04, 0.0000e+00, 1.7157e-01],\n",
       "          [0.0000e+00, 1.1570e-03, 1.4782e-01]],\n",
       "\n",
       "         [[1.2283e-03, 0.0000e+00, 1.3519e-01],\n",
       "          [1.2280e-03, 0.0000e+00, 1.3768e-01],\n",
       "          [0.0000e+00, 7.3028e-04, 2.0885e-01],\n",
       "          ...,\n",
       "          [3.8107e-04, 0.0000e+00, 4.0858e-01],\n",
       "          [8.8149e-04, 0.0000e+00, 1.8722e-01],\n",
       "          [7.2787e-04, 0.0000e+00, 2.0816e-01]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px_tminus1_giv_xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "813b7f46-7726-4729-a299-bc61557e6f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(\n",
    "            torch.sum(\n",
    "                cat_diff.forward_conditionals[2:] * (\n",
    "                    stuff * torch.log(\n",
    "                        (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "                    )\n",
    "                ),\n",
    "                axis=-1\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b01c4bb4-af57-480e-94b1-ea888dd1b1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([94, 94, 94]),\n",
       " array([24, 24, 24]),\n",
       " array([15, 15, 15]),\n",
       " array([0, 1, 2]))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    "    ).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8ae5c98c-2e1e-4b90-9cd8-9219e532fc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff[94,24,15,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e20f9b6f-72ad-4eaf-8c2e-045948a6179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    ")[94,24,15,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "50930109-7282-4f7a-b9b8-be4347080f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(torch.sum(\n",
    "    cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    "    ),\n",
    "    axis=-1\n",
    ").detach().numpy()).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2c7b9ca2-b68b-423e-ba29-387f1223cf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([94]), array([24]), array([15]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(torch.sum(\n",
    "    cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    "    ),\n",
    "    axis=-1\n",
    ").detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c95f773d-cdde-440a-8b0f-92e5f7d93407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0332, 0.6706, 0.9716, 0.9757, 0.9757, 0.9757, 1.0741, 0.7729, 1.1290,\n",
       "        0.9757, 0.9757, 1.4398, 0.9554, 0.7639, 0.8608,    nan, 0.7205, 0.7551,\n",
       "        1.3197, 1.0787, 1.0720, 1.4066, 0.6798, 1.0329, 1.2583, 1.5059, 1.4623,\n",
       "        0.8676, 0.9757, 0.8594, 1.1232, 0.9757, 0.9757, 0.9757, 1.1720, 1.2588,\n",
       "        0.7667, 0.7437, 1.1948, 0.9847, 0.7845, 0.5300, 0.6469, 1.4376, 1.0879,\n",
       "        0.9078, 0.7355, 1.7366, 1.0102, 1.1947, 0.6780, 1.0162, 1.2185, 1.2742,\n",
       "        1.0918, 0.9757, 1.2834, 0.9914, 0.9757, 1.0105, 1.1534, 1.3210, 1.2183,\n",
       "        0.6016, 1.0976, 0.8873, 1.2643, 1.6309, 0.6532, 1.2003, 1.3970, 1.0385,\n",
       "        0.8668, 0.9967, 1.5562, 0.8305, 1.2290, 0.5932, 0.9200, 1.2263, 1.3277,\n",
       "        0.9840, 1.3741, 0.9757, 0.9794, 1.1538, 0.9106, 1.0421, 1.3159, 0.8671,\n",
       "        0.7996, 1.5560, 1.2296, 1.1848, 1.4853, 0.9757, 1.4080, 0.9757, 1.1681,\n",
       "        0.9757], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(\n",
    "    cat_diff.forward_conditionals[2:] * (\n",
    "        stuff * torch.log(\n",
    "            (stuff + 1e-6)/(px_tminus1_giv_xt+1e-6)\n",
    "        )\n",
    "    ),\n",
    "    axis=-1\n",
    ")[94][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e8b9276e-d662-439a-9b61-e4601a77a29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98, 128, 100, 3])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.forward_conditionals[2:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b3442cad-93d6-4181-b590-a5d69354d056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Lt0_t1_loss = cat_diff.L_t0t1(Y_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8da26d15-6bcb-4458-ab25-1de1515e4d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1005, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lt0_t1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e29f0c8f-82d6-4f43-bf68-2e46840e5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ltminus1    = cat_diff.L_tminus1(Y_spins, noised_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d478c13f-58bb-4f5d-a8c8-3ad813a4c0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12800, 128])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff.eval()\n",
    "\n",
    "t = ts.reshape(ts.shape[0] * ts.shape[1], 1)\n",
    "\n",
    "time_encoding = cat_diff.denoiser.forward_time_1(t)\n",
    "cat_diff.denoiser.forward_time_2(time_encoding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8d6daebf-99e6-42d5-8433-3fccc5d68420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  ..., 37.5615, 37.5615, 37.5615],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(time_encoding[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "dfe5f3b9-ea2a-4c93-964a-31ce0f11bb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ltminus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3fc83300-174d-4b94-ae57-f94084904032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noised_samples[1][3][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "faa4c9ab-ba8f-4ab6-a816-f799cc930644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cd5c0-d307-41c7-b29f-bbaa18cf2b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
